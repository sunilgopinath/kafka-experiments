# **Event-Driven Microservices with Kafka**

## **ğŸš€ Overview**
This project implements an **event-driven microservices architecture** using **Apache Kafka**. We built a **scalable E-commerce Order Processing System** with **Event Sourcing**, where each microservice publishes and consumes **domain events** asynchronously.

## **ğŸ› ï¸ Technologies Used**
- **Go (Golang)** - Microservice implementation
- **Apache Kafka** - Event streaming platform
- **Docker & Docker Compose** - Service orchestration
- **PostgreSQL (Optional)** - Database for persistence
- **Kafka Consumer Groups** - Parallel processing
- **Exponential Backoff & Retry Mechanisms** - Fault tolerance
- **Dead Letter Queue (DLQ)** - Handling failures gracefully
  
## **ğŸ“Œ Architecture**

```
USER â†’ Order Service â†’ order_created â†’ Kafka
              â†³ Payment Service â†’ order_paid â†’ Kafka
              â†³ Inventory Service â†’ inventory_reserved/inventory_failed â†’ Kafka
              â†³ Shipping Service â†’ order_shipped â†’ Kafka
              â†³ Delivery Service â†’ order_delivered â†’ Kafka
              â†³ Notification Service â†’ Sends user updates
```

- **Each service listens for relevant Kafka topics.**
- **Microservices communicate via domain events (not direct API calls).**
- **Kafka retains a history of events (Event Sourcing).**
- **Event Replay allows restoring state from Kafka topics.**

## **ğŸ“‚ Project Structure**
```
.
â”œâ”€â”€ cmd
â”‚   â”œâ”€â”€ order_service        # Handles order creation
â”‚   â”‚   â””â”€â”€ main.go
â”‚   â”œâ”€â”€ payment_service      # Handles payment processing
â”‚   â”‚   â””â”€â”€ main.go
â”‚   â”œâ”€â”€ shipping_service     # Handles shipping
â”‚   â”‚   â””â”€â”€ main.go
â”‚   â”œâ”€â”€ delivery_service     # Handles order delivery
â”‚   â”‚   â””â”€â”€ main.go
â”‚   â”œâ”€â”€ inventory_service    # Manages stock availability
â”‚   â”‚   â””â”€â”€ main.go
â”‚   â”œâ”€â”€ notification_service # Sends user notifications
â”‚   â”‚   â””â”€â”€ main.go
â”‚
â”œâ”€â”€ internal
â”‚   â”œâ”€â”€ models               # Shared domain models
â”‚   â”‚   â””â”€â”€ order.go
â”‚   â”œâ”€â”€ kafka                # Kafka utility functions
â”‚   â”‚   â”œâ”€â”€ producer.go
â”‚   â”‚   â”œâ”€â”€ consumer.go
â”‚
â”œâ”€â”€ docker-compose.yml        # Kafka + Zookeeper setup
â”œâ”€â”€ go.mod                    # Go dependencies
â”œâ”€â”€ go.sum                    # Go dependency hashes
â””â”€â”€ README.md                 # Project documentation
```

## **ğŸ“ Order Event Model** (Shared Across Microservices)
```go
package models

type OrderEvent struct {
    OrderID   string `json:"orderId"`
    UserID    string `json:"userId"`
    Status    string `json:"status"`
    Timestamp int64  `json:"timestamp"`
}
```

---

# **ğŸš€ Getting Started**

```bash
$> git clone git@github.com:sunilgopinath/kafka-experiments.git
```

## **1ï¸âƒ£ Setup Kafka with Docker**
Run the following command to start Kafka & Zookeeper:
```sh
docker-compose up -d
```

âœ… **Verify Kafka is running:**
```sh
docker ps | grep kafka
CONTAINER ID   IMAGE                 COMMAND                  CREATED          STATUS          PORTS                    NAMES
5a992aa5f7bf   bitnami/kafka:3.6.1   "/opt/bitnami/scriptâ€¦"   15 minutes ago   Up 15 minutes   0.0.0.0:9092->9092/tcp   kafka-experiments-kafka-1
```


## Create topic

```bash
$> docker exec -it $(docker ps -q -f name=kafka) kafka-topics.sh --create --topic payments --partitions 3 --replication-factor 1 --bootstrap-server localhost:9092
```

### Test topic creation

```bash
â¯ docker exec -it $(docker ps -q -f name=kafka) kafka-topics.sh --list --bootstrap-server localhost:9092
payments
```

## Usage

terminal 1

```bash
â¯ go run producer/producer.go

Message delivered to payments[1]@0
```


terminal 2

```bash
â¯ go run consumer/consumer.go
Received: {"amount":100,"paymentId":"p1","userId":"u1"}
```

## Write to database upon consumer

Please see [database documentation](./docs/db.md) for setup

## Writing to Dead Letter Queue

```bash
docker exec -it $(docker ps -q -f name=kafka) kafka-topics.sh --create --topic dead_letter_queue --partitions 3 --replication-factor 1 --bootstrap-server localhost:9092
```

### Test DLQ

```bash
docker exec -it $(docker ps -q -f name=kafka) kafka-topics.sh --list --bootstrap-server localhost:9092
```

## Notification System

Create two queues
1. high priority
2. low priority

```bash
docker exec -it $(docker ps -q -f name=kafka) kafka-topics.sh --create --topic high_priority_notifications --partitions 3 --replication-factor 1 --bootstrap-server localhost:9092

docker exec -it $(docker ps -q -f name=kafka) kafka-topics.sh --create --topic low_priority_notifications --partitions 3 --replication-factor 1 --bootstrap-server localhost:9092
```

## Order Service

### **2ï¸âƒ£ Create Kafka Topics**
```sh
docker exec -it $(docker ps -q -f name=kafka) kafka-topics.sh --create --topic order_created --partitions 3 --replication-factor 1 --bootstrap-server localhost:9092

docker exec -it $(docker ps -q -f name=kafka) kafka-topics.sh --create --topic order_paid --partitions 3 --replication-factor 1 --bootstrap-server localhost:9092

docker exec -it $(docker ps -q -f name=kafka) kafka-topics.sh --create --topic order_shipped --partitions 3 --replication-factor 1 --bootstrap-server localhost:9092

docker exec -it $(docker ps -q -f name=kafka) kafka-topics.sh --create --topic order_delivered --partitions 3 --replication-factor 1 --bootstrap-server localhost:9092
```
âœ… **Verify topics:**
```sh
docker exec -it $(docker ps -q -f name=kafka) kafka-topics.sh --list --bootstrap-server localhost:9092
```

---

# **ğŸ› ï¸ Running the Microservices**

## **Start All Services in Separate Terminals**
```sh
go run cmd/order_service/main.go
```
```sh
go run cmd/payment_service/main.go
```
```sh
go run cmd/shipping_service/main.go
```
```sh
go run cmd/delivery_service/main.go
```
```sh
go run cmd/inventory_service/main.go
```
```sh
go run cmd/notification_service/main.go
```

âœ… **Expected Output:**
```
ğŸ›’ Order Created: order1
ğŸ’° Payment Processed: order1
âœ… Inventory Reserved for Order order1
ğŸ“¦ Shipping Order: order1
ğŸšš Order Delivered: order1
ğŸ“© Notification sent: Order shipped
```

---

# **ğŸ“Œ Event Replay (Event Sourcing)**
If a service **crashes**, we can replay events to rebuild its state.
```sh
docker exec -it $(docker ps -q -f name=kafka) kafka-console-consumer.sh --topic order_created --from-beginning --bootstrap-server localhost:9092
```
âœ… **Expected Output:**
```
{"orderId":"order1","userId":"user1","status":"order_created","timestamp":1711345827}
```

---

# **ğŸ“Š Monitoring & Debugging**
âœ… **View consumer group assignments:**
```sh
docker exec -it $(docker ps -q -f name=kafka) kafka-consumer-groups.sh --describe --group order-service --bootstrap-server localhost:9092
```

âœ… **View Dead Letter Queue (DLQ) events:**
```sh
docker exec -it $(docker ps -q -f name=kafka) kafka-console-consumer.sh --topic dead_letter_queue --from-beginning --bootstrap-server localhost:9092
```

---

# **ğŸ› ï¸ Next Steps**
ğŸ”¹ **Add Retries & Exponential Backoff for Failures**
ğŸ”¹ **Implement DLQ Handling for Fault-Tolerant Processing**
ğŸ”¹ **Optimize Performance with Kafka Streams & Schema Registry**

ğŸš€ **Happy Coding!** ğŸ¯